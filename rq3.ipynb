{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": "pip install python-terrier==0.10.0 fast-forward-indexes==0.2.0",
   "id": "edf4c1c76102bc49",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Start Terrier",
   "id": "5d49ded35bcef130"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pyterrier as pt\n",
    "\n",
    "if not pt.started():\n",
    "    pt.init(\n",
    "        tqdm=\"notebook\",\n",
    "        boot_packages=[\"com.github.terrierteam:terrier-prf:-SNAPSHOT\"]\n",
    "    )"
   ],
   "id": "d119fa68045fcdec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Set required dataset and index parameters",
   "id": "32ca133f485c9ea1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "DATASET_NAME = \"beir/nfcorpus\"\n",
    "TESTSET_NAME = \"beir/nfcorpus/test\"\n",
    "BM25_INDEX_PATH = 'indices/nfcorpus'\n",
    "INDEX_PATH = 'indexes/ffindex_nfcorpus_tct_colbert_msmarco.h5'\n",
    "FIELDS = [\"text\"]\n",
    "\n",
    "SHOULD_RUN_GRID = True\n",
    "DEVSET_NAME = \"irds:beir/nfcorpus/train\""
   ],
   "id": "22eeae897a125187",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load datasets",
   "id": "eeabe505056ac7bd"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import ir_datasets\n",
    "dataset = pt.get_dataset('irds:' + DATASET_NAME)\n",
    "ir_ds = ir_datasets.load(DATASET_NAME)"
   ],
   "id": "37d3efd416d824d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load or Create the sparse index",
   "id": "ac161c9ea790197f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "\n",
    "idx_path = Path(BM25_INDEX_PATH).absolute()\n",
    "\n",
    "index_ref = pt.index.IterDictIndexer(\n",
    "    str(idx_path),\n",
    "    blocks=True,\n",
    "    meta={'docno': ir_ds.docs_metadata()['fields']['doc_id']['max_len'] },\n",
    ").index(dataset.get_corpus_iter(), fields=FIELDS)\n",
    "index_ref = index_ref.to_memory()"
   ],
   "id": "596d42a77efb0b69",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialise BM25 and RM3",
   "id": "deaea5e7945ee66b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from pyterrier.measures import RR, nDCG, MAP\n",
    "\n",
    "index = pt.IndexFactory.of(str(idx_path))\n",
    "\n",
    "bm25 = pt.BatchRetrieve(index, wmodel=\"BM25\")\n",
    "rm3 = pt.rewrite.RM3(index)\n",
    "testset = pt.get_dataset('irds:' + TESTSET_NAME)"
   ],
   "id": "960ec6d9cd21056d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Initialise TCT-ColBERT Encoder",
   "id": "1b20b920cb64340d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fast_forward.encoder import TCTColBERTQueryEncoder, TCTColBERTDocumentEncoder\n",
    "import torch\n",
    "\n",
    "q_encoder = TCTColBERTQueryEncoder(\"castorini/tct_colbert-msmarco\")\n",
    "d_encoder = TCTColBERTDocumentEncoder(\n",
    "    \"castorini/tct_colbert-msmarco\",\n",
    "    device=\"cuda:0\" if torch.cuda.is_available() else \"cpu\",\n",
    ")\n",
    "q_encoder([\"Test query 1\", \"Test query 2\"])"
   ],
   "id": "f7cccceb324ab923",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load the FF-index",
   "id": "6b6eb3518075897"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fast_forward import OnDiskIndex, Mode\n",
    "\n",
    "ff_index = OnDiskIndex.load(\n",
    "    Path(INDEX_PATH), query_encoder=q_encoder, mode=Mode.MAXP\n",
    ")\n",
    "ff_index = ff_index.to_memory()"
   ],
   "id": "385d13226ed95ea1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Create re-ranking stage\n",
   "id": "3fd65ab0065626a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from fast_forward.util.pyterrier import FFScore\n",
    "from fast_forward.util.pyterrier import FFInterpolate\n",
    "\n",
    "ff_score = FFScore(ff_index)\n",
    "candidates = (bm25 % 5)(testset.get_topics('text')) # Get the candidates\n",
    "re_ranked = ff_score(candidates)\n",
    "ff_int = FFInterpolate(alpha=0.05)\n",
    "ff_int(re_ranked)"
   ],
   "id": "b4e0c1d041a0a332",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Run exhausive search for the parameters",
   "id": "d57bd1f13066abc6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if SHOULD_RUN_GRID:\n",
    "    devset = pt.get_dataset(DEVSET_NAME)\n",
    "    pt.GridSearch(\n",
    "        bm25 % 5 >> rm3 >> bm25 % 100,\n",
    "        {rm3: {\"fb_docs\": [3,5,7,10], \"fb_terms\": [3,10,15]}},\n",
    "        devset.get_topics(\"text\"),\n",
    "        devset.get_qrels(),\n",
    "        metric=\"recip_rank\",\n",
    "        verbose=True,\n",
    "    )"
   ],
   "id": "2ccf19d2729c063f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print(rm3.fb_docs)\n",
    "print(rm3.fb_terms)"
   ],
   "id": "8c0e42fe0a1eef8d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Output the experiments' results",
   "id": "610106f796782030"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "steps = ['10', '50', '100', '500', '1000', '5000', '25000']\n",
    "\n",
    "result = pt.Experiment(\n",
    "    [\n",
    "        bm25 % 1000 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 1000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 10 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 10 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 50 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 50 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 100 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 100 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 500 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 500 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 1000 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 1000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 5000 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 5000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 25000 >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 25000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "    ],\n",
    "    testset.get_topics('text'),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10],\n",
    "    names=[\n",
    "        \"TCT-ColBERT_10\",\n",
    "        \"RM3+TCT-ColBERT_10\",\n",
    "        \"TCT-ColBERT_50\",\n",
    "        \"RM3+TCT-ColBERT_50\",\n",
    "        \"TCT-ColBERT_100\",\n",
    "        \"RM3+TCT-ColBERT_100\",\n",
    "        \"TCT-ColBERT_500\",\n",
    "        \"RM3+TCT-ColBERT_500\",\n",
    "        \"TCT-ColBERT_1000\",\n",
    "        \"RM3+TCT-ColBERT_1000\",\n",
    "        \"TCT-ColBERT_5000\",\n",
    "        \"RM3+TCT-ColBERT_5000\",\n",
    "        \"TCT-ColBERT_25000\",\n",
    "        \"RM3+TCT-ColBERT_25000\",\n",
    "    ],\n",
    ")\n",
    "result"
   ],
   "id": "9c42ebb0c1709305",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Statistical T-test comparing the two models",
   "id": "653fdac3150b6b15"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "result = pt.Experiment(\n",
    "    [\n",
    "        bm25 % 5 >> pt.rewrite.RM3(index) >> bm25 % 1000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "        bm25 % 5 >> rm3 >> bm25 % 1000 >> pt.rewrite.reset() >> ff_score >> ff_int,\n",
    "    ],\n",
    "    testset.get_topics('text'),\n",
    "    testset.get_qrels(),\n",
    "    eval_metrics=[RR @ 10, nDCG @ 10, MAP @ 100],\n",
    "    names=[\n",
    "        \"RM3+TCT-ColBERT\",\n",
    "        \"RM3+TCT-ColBERT_tuned\"\n",
    "    ],\n",
    "    baseline=0\n",
    ")\n",
    "result"
   ],
   "id": "10ce4e70068174e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
